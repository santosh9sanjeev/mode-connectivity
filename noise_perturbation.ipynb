{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import clip\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import math\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torchvision.transforms import *\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data.dataset import Subset\n",
    "from torchvision.transforms import InterpolationMode\n",
    "BICUBIC = InterpolationMode.BICUBIC\n",
    "\n",
    "def _convert_image_to_rgb(image):\n",
    "    return image.convert(\"RGB\")\n",
    "\n",
    "\n",
    "def _transform(n_px):\n",
    "    return Compose([\n",
    "        Resize(n_px, interpolation=BICUBIC),\n",
    "        CenterCrop(n_px),\n",
    "        _convert_image_to_rgb,\n",
    "        ToTensor(),\n",
    "        Normalize((0.48145466, 0.4578275, 0.40821073), (0.26862954, 0.26130258, 0.27577711)),\n",
    "    ])\n",
    "\n",
    "transforms = _transform(224)\n",
    "\n",
    "idxs = np.load('cifar1098_idxs.npy').astype('int')\n",
    "indices = []\n",
    "for i in range(len(idxs)):\n",
    "  if idxs[i]:\n",
    "    indices.append(i)\n",
    "# print(idxs)\n",
    "# print(indices)\n",
    "val = CIFAR10(root='./data', train=True, download=True, transform=transforms)\n",
    "val = Subset(val, indices)\n",
    "test = CIFAR10(root='./data', train=False, download=True, transform=transforms)\n",
    "\n",
    "valloader = torch.utils.data.DataLoader(val,\n",
    "                                        batch_size=128,\n",
    "                                        shuffle=False,\n",
    "                                        num_workers=2,\n",
    "                                        drop_last=False)\n",
    "testloader = torch.utils.data.DataLoader(test,\n",
    "                                         batch_size=128,\n",
    "                                         shuffle=False,\n",
    "                                         num_workers=2,\n",
    "                                         drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model):\n",
    "  preds = []\n",
    "  labels = []\n",
    "  for x, y in tqdm(valloader):\n",
    "    x = x.to(device)\n",
    "    y = y.to(device)\n",
    "    preds.append(model(x).argmax(dim=1))\n",
    "    labels.append(y)\n",
    "  return torch.mean((torch.cat(preds) == torch.cat(labels)).float()).item()\n",
    "\n",
    "def test(model):\n",
    "  preds = []\n",
    "  labels = []\n",
    "  for x, y in tqdm(testloader):\n",
    "    x = x.to(device)\n",
    "    y = y.to(device)\n",
    "    preds.append(model(x).argmax(dim=1))\n",
    "    labels.append(y)\n",
    "  return torch.mean((torch.cat(preds) == torch.cat(labels)).float()).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelWrapper(torch.nn.Module):\n",
    "    def __init__(self, model, feature_dim, num_classes, normalize=False, initial_weights=None):\n",
    "        super(ModelWrapper, self).__init__()\n",
    "        self.model = model\n",
    "        self.classification_head = torch.nn.Linear(feature_dim, num_classes)\n",
    "        self.normalize = normalize\n",
    "        if not self.normalize:\n",
    "            print('normalize skipped.')\n",
    "\n",
    "        if initial_weights is not None and type(initial_weights) == tuple:\n",
    "            print('tuple.')\n",
    "            w, b = initial_weights\n",
    "            self.classification_head.weight = torch.nn.Parameter(w.clone())\n",
    "            self.classification_head.bias = torch.nn.Parameter(b.clone())\n",
    "        else:\n",
    "            if initial_weights is None:\n",
    "                initial_weights = torch.zeros_like(self.classification_head.weight)\n",
    "                torch.nn.init.kaiming_uniform_(initial_weights, a=math.sqrt(5))\n",
    "            self.classification_head.weight = torch.nn.Parameter(initial_weights.clone())\n",
    "            # Note: modified. Initial bug in forgetting to zero bias.\n",
    "            self.classification_head.bias = torch.nn.Parameter(torch.zeros_like(self.classification_head.bias))\n",
    "\n",
    "        # Note: modified. Get rid of the language part.\n",
    "        delattr(self.model, 'transformer')\n",
    "\n",
    "    def forward(self, images):\n",
    "        features = self.model.encode_image(images).float()\n",
    "        if self.normalize:\n",
    "            features = features / features.norm(dim=-1, keepdim=True)\n",
    "        logits = self.classification_head(features)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading checkpoint_10.1.pt\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda:2' if torch.cuda.is_available() else 'cpu'\n",
    "state_dicts = []\n",
    "\n",
    "for f in sorted(os.listdir()):\n",
    "  if f[-2:] == 'pt':\n",
    "    print(f'Loading {f}')\n",
    "    state_dicts.append(torch.load(f, map_location=device))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(state_dicts, alphal):\n",
    "  model, _ = clip.load('ViT-B/32')\n",
    "  feature_dim = state_dicts[0]['classification_head.weight'].shape[1]\n",
    "  num_classes = state_dicts[0]['classification_head.weight'].shape[0]\n",
    "  normalize = True\n",
    "  model = ModelWrapper(model, feature_dim, num_classes, normalize)\n",
    "  sd = {k : state_dicts[0][k].clone() * alphal[0] for k in state_dicts[0].keys()}\n",
    "  for i in range(1, len(state_dicts)):\n",
    "      for k in state_dicts[i].keys():\n",
    "          sd[k] = sd[k] + state_dicts[i][k].clone() * alphal[i]\n",
    "  model.load_state_dict(sd)\n",
    "  model = model.to(device)\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_random_noise_to_model(model, noise_factor=0.01):\n",
    "    with torch.no_grad():\n",
    "        for param in model.parameters():\n",
    "            # Check if the parameter is learnable (has gradients)\n",
    "            if param.requires_grad:\n",
    "                # Generate random noise of the same shape as the parameter\n",
    "                random_noise = torch.randn_like(param) * noise_factor\n",
    "                # Add random noise to the parameter\n",
    "                param.add_(random_noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8d5640694844c4287409db9f3b6bb4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ecefdb29146347a3a67753cfd7af39bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9825999736785889 0.9769999980926514\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2111f2f25dae4db39216208bb5e03f55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f97fbcf8b9f14f3aaecfd6ee057239a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9715999960899353 0.9645999670028687\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d74bbc96ed7a412b80316349feace4ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec4c179be6d24375b4c06b0cd1215a83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9717999696731567 0.9670999646186829\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8271eca8fd5450983d20bdc4a6238c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63fe5957845546219aa3f82acd8b47db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9684000015258789 0.9627999663352966\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d71beff8cd6c4e898cbaf73954f51f11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9961fd52b3a5411c84eb0763191b106d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9703999757766724 0.9644999504089355\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8ee037be1644e49a152c66e7a4900a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a41c7d1185a949fda6e540ccd797d95a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9699999690055847 0.965999960899353\n"
     ]
    }
   ],
   "source": [
    "state_dicts_2 = []\n",
    "val_results = []\n",
    "test_results = []\n",
    "import copy\n",
    "model, _ = clip.load('ViT-B/32')\n",
    "feature_dim = state_dicts[0]['classification_head.weight'].shape[1]\n",
    "num_classes = state_dicts[0]['classification_head.weight'].shape[0]\n",
    "normalize = True\n",
    "model = ModelWrapper(model, feature_dim, num_classes, normalize)\n",
    "state_dicts_2.append(torch.load('checkpoint_10.1.pt', map_location=device))\n",
    "model.load_state_dict(state_dicts_2[0])\n",
    "\n",
    "model = model.to(device)\n",
    "real_model = copy.deepcopy(model)\n",
    "val_results.append(validate(model))\n",
    "test_results.append(test(model))\n",
    "print(val_results[-1], test_results[-1])\n",
    "for j in range(5):\n",
    "  noise_factor = 2e-3  # You can adjust this value\n",
    "  add_random_noise_to_model(model, noise_factor)\n",
    "  state_dicts_2.append(model.state_dict())\n",
    "  \n",
    "  val_results.append(validate(model))\n",
    "  test_results.append(test(model))\n",
    "  print(val_results[-1], test_results[-1])\n",
    "  model = copy.deepcopy(real_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9825999736785889, 0.9815999865531921, 0.9824000000953674, 0.9819999933242798, 0.9817999601364136, 0.9811999797821045] [0.9769999980926514, 0.9765999913215637, 0.976699948310852, 0.9751999974250793, 0.976099967956543, 0.9767999649047852]\n"
     ]
    }
   ],
   "source": [
    "print(val_results, test_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "print(len(state_dicts_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38720def190644d9b0f1415980928d5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9765999913215637\n"
     ]
    }
   ],
   "source": [
    "alphal = [1 / len(state_dicts_2) for i in range(len(state_dicts_2))]\n",
    "model = get_model(state_dicts_2, alphal)\n",
    "test_results.append(test(model))\n",
    "print(test_results[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "model_soups",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
